# How It Works

[Installation](install.md)

[Configure LAN setup](lan_setup.md)

[Getting Started](getting_started.md)

[How It Works](how_it_works.md)

[config.yaml Reference](docs/config.md)

The app is built as a modular pipeline where each stage is configurable, pluggable, and designed for customization or replacement.

Here’s the high-level flow:

---

### 1. Audio Capture  
Audio is streamed from the microphone in small, overlapping chunks.  
(You can optionally substitute file input or other audio sources.)

---

### 2. Transcription  
Each audio chunk is transcribed using a local Whisper-compatible model (e.g., Faster-Whisper or whisper-mlx).  
Timestamps are preserved for accurate segment alignment and playback sync.

---

### 3. Shallow Analysis  
Transcribed segments are passed to a lightweight local LLM configured as the **shallow model**.

- Runs a structured prompt (see `src/rachel/utils/prompts.py`)
- Extracts things like:
  - **People**
  - **Places**
  - **Unusual Concepts**
  - **Potential Claims**

This step is optimized to complete in under 1 second for smooth UI updates.  
If **no claims** are detected, the segment is streamed immediately to the frontend and the pipeline ends there.

---

### 4. LoRA Adapters (Optional but Recommended)

The shallow LLM can optionally load a **LoRA adapter**—a lightweight fine-tuned layer that improves accuracy on spoken content like podcasts.

- Greatly improves entity recognition and claim spotting
- Trained on real podcast data for domain specificity
- Keeps inference fast and lightweight (~100MB adapter)

> The default adapter provided is for **non-commercial research/demo use only** (see license).  
> You can also train your own—see `rachel/docker/Dockerfile.train`

---

### 5. Semantic Filtering  
If a segment contains a potential claim, it passes through a **semantic deduplication filter**.

- Compares against recent conversation context (using MiniLM embeddings)
- Filters out claims that are near-duplicates of recent content
- Reduces redundant deep inference and improves UX

> Only **non-duplicate** segments continue to the deep analysis stage.

---

### 6. Deep Analysis (selectively requested)  
If a claim is novel and interesting, it’s routed to a **deep LLM** (e.g., GPT-4, Claude) for enrichment.

This deeper analysis returns:

- Clarifications and corrections
- Factual expansion with context
- Optional summaries or citations

> Selective routing helps control latency and reduce API costs while preserving insight quality.

---

### API Docs

The backend is built with FastAPI and includes live API documentation.

Once the server is running, visit:

- [http://localhost:8000/docs](http://localhost:8000/docs) — Swagger UI (interactive)
- [http://localhost:8000/redoc](http://localhost:8000/redoc) — Redoc (read-only)

The OpenAPI spec is autogenerated from the codebase.
